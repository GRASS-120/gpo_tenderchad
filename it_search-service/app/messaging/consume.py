#!/usr/bin/env python
import pika, sys, os, time

# worker-queue / task queue - позволяет распараллеливать задачи. то есть мы создаем несколько
# воркеров (копий) процесса, отвечающего за принятие сообщений

# message acknowledgment (ack) - для того, чтобы точно доставить задачу в очередь и не потерять ее,
# нужно быть уверенным, что она дошла до очереди.
# для этого используется подтверждение - то есть если сообщение дошло и было обработано, присылается уведомление отправителю
# о том, что с сообщением все норм и можно его удалить (дя экономии памяти). если уведомления нет из-за проблем
# с очередью, то задача пересылается в другую очередь (воркер) или в текущую после перезагрузки

def consume_messages():
  # подключение
  connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
  channel = connection.channel()

  # создание очереди - желательно всегда прописывать и в отправителе, и получателе
  # durable - в очереди с такой меткой сообщения не удаляться даже при завершении работы сервера (нужно еще пометить)
  # сообщение на стороне отправителя как persistance
  channel.queue_declare(queue='it_search_queue', durable=True)

  # функция вызывается при получении сообщения
  def callback(ch, method, properties, body):
    print(f" [x] Received {body.decode()}")
    time.sleep(body.count(b'.') )
    print(" [x] Done")
    ch.basic_ack(delivery_tag = method.delivery_tag)  # !

  # настройка прослушивания очереди
  channel.basic_consume(queue='hello', on_message_callback=callback)
  # auto_ack=True - по умолчанию нужны подтверждения 

  # prefetch_count=1 - пропускная способность очереди. то есть, при 1 она может обрабатывать только одно сообщение.
  # это значит, что пока мы не получим подтверждение о обработке одного сообщения, другое обрабатываться не начнет
  # поэтому если очередь занята, сообщение перенаправиться в другой воркер
  channel.basic_qos(prefetch_count=1)
  # запускаем бесконечный цикл прослушивания (мб его запускать в lifespan?)
  channel.start_consuming()